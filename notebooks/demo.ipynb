{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avatar Presentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transcript Generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a transcript for a presentation based on the input slide in pptx format using llm \n",
    "from pptx import Presentation\n",
    "import openai\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "# Initialize OpenAI client\n",
    "llm = openai.OpenAI(api_key=\"your-api-key\")\n",
    "\n",
    "# Load the presentation\n",
    "pptx_path = \"MASc_Seminar_final.pptx\"\n",
    "presentation = Presentation(pptx_path)\n",
    "\n",
    "# Process each slide\n",
    "transcripts = []\n",
    "for idx, slide in enumerate(presentation.slides, 1):\n",
    "    # Extract all text from the slide\n",
    "    slide_content = []\n",
    "    for shape in slide.shapes:\n",
    "        if hasattr(shape, \"text\") and shape.text.strip():\n",
    "            slide_content.append(shape.text.strip())\n",
    "    \n",
    "    if not slide_content:\n",
    "        continue\n",
    "        \n",
    "    # Join all text content\n",
    "    full_content = \"\\n\".join(slide_content)\n",
    "    \n",
    "    # Generate transcript using LLM\n",
    "    prompt = f\"\"\"Please generate a natural, conversational transcript for the following presentation slide content. \n",
    "    Make it sound like someone giving a presentation, with proper transitions and explanations.\n",
    "    \n",
    "    Slide content:\n",
    "    {full_content}\n",
    "    \n",
    "    Transcript:\"\"\"\n",
    "    \n",
    "    response = llm.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=500\n",
    "    )\n",
    "    \n",
    "    transcript = response.choices[0].message.content.strip()\n",
    "    \n",
    "    # Store results\n",
    "    slide_data = {\n",
    "        \"slide_number\": idx,\n",
    "        \"original_content\": full_content,\n",
    "        \"transcript\": transcript\n",
    "    }\n",
    "    transcripts.append(slide_data)\n",
    "    \n",
    "    print(f\"Processed slide {idx}\")\n",
    "\n",
    "# Save transcripts to a JSON file\n",
    "output_file = \"presentation_transcripts.json\"\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(transcripts, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\nTranscripts have been saved to {output_file}\")\n",
    "\n",
    "# Print first transcript as example\n",
    "if transcripts:\n",
    "    print(\"\\nExample transcript for first slide:\")\n",
    "    print(transcripts[0][\"transcript\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voice Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "# Load the transcripts\n",
    "with open(\"presentation_transcripts.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    transcripts = json.load(f)\n",
    "\n",
    "# Create output directory for audio files if it doesn't exist\n",
    "output_dir = Path(\"audio_files\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Minimax TTS API configuration\n",
    "api_url = \"https://api.minimax.chat/v1/t2a_v2\"\n",
    "api_key = \"your-api-key\"  # Replace with your actual API key\n",
    "\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {api_key}\"\n",
    "}\n",
    "\n",
    "# Process each transcript\n",
    "for slide_data in transcripts:\n",
    "    slide_number = slide_data[\"slide_number\"]\n",
    "    transcript = slide_data[\"transcript\"]\n",
    "    \n",
    "    # Prepare the request payload\n",
    "    payload = {\n",
    "        \"model\": \"speech-02-hd\",\n",
    "        \"text\": transcript,\n",
    "        \"stream\": False,\n",
    "        \"language_boost\": \"auto\",\n",
    "        \"output_format\": \"hex\",\n",
    "        \"voice_setting\": {\n",
    "            \"voice_id\": \"male-qn-qingse\",\n",
    "            \"speed\": 1,\n",
    "            \"vol\": 1,\n",
    "            \"pitch\": 0,\n",
    "            \"emotion\": \"happy\"\n",
    "        },\n",
    "        \"audio_setting\": {\n",
    "            \"sample_rate\": 32000,\n",
    "            \"bitrate\": 128000,\n",
    "            \"format\": \"mp3\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Make the API request\n",
    "    try:\n",
    "        response = requests.post(api_url, headers=headers, json=payload)\n",
    "        response.raise_for_status()  # Raise an exception for HTTP errors\n",
    "        \n",
    "        # Get the audio data from the response\n",
    "        audio_data = response.json().get(\"audio\")\n",
    "        \n",
    "        if audio_data:\n",
    "            # Convert hex to binary and save to file\n",
    "            audio_binary = bytes.fromhex(audio_data)\n",
    "            output_file = output_dir / f\"slide_{slide_number}.mp3\"\n",
    "            \n",
    "            with open(output_file, \"wb\") as f:\n",
    "                f.write(audio_binary)\n",
    "            \n",
    "            print(f\"Generated audio for slide {slide_number}\")\n",
    "            \n",
    "            # Add a small delay to avoid rate limiting\n",
    "            time.sleep(1)\n",
    "        else:\n",
    "            print(f\"No audio data received for slide {slide_number}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error generating audio for slide {slide_number}: {str(e)}\")\n",
    "\n",
    "print(\"Audio generation complete!\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
